{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing steps such as feature extraction, feature scaling, and dimensionality reduction, to name just a few.\n",
    "Build 3 pipelines, each with a different estimator (classification algorithm), using default hyperparameters:\n",
    "\n",
    "Logisitic Regression\n",
    "\n",
    "Support Vector Machine\n",
    "\n",
    "Decision Tree\n",
    "\n",
    "To demonstrate pipeline transforms, will perform:\n",
    "\n",
    "feature scaling\n",
    "dimensionality reduction, using PCA to project data onto 2 dimensional space\n",
    "We will then end with fitting to our final estimators.\n",
    "\n",
    "Followup with scoring test data\n",
    "Compare pipeline model accuracies\n",
    "Identify the \"best\" model, meaning that which has the highest accuracy on our test data\n",
    "Persist (save to file) the entire pipeline of the \"best\" model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression pipeline test accuracy: 0.852\n",
      "Support Vector Machine pipeline test accuracy: 0.852\n",
      "Decision Tree pipeline test accuracy: 0.738\n",
      "Classifier with best accuracy: Logistic Regression\n",
      "Saved Logistic Regression pipeline to file\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "# Load and split the data\n",
    "dataset = pd.read_csv('../machine/heart.csv')\n",
    "X = dataset.drop('target',axis =1)\n",
    "y = dataset['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Construct some pipelines\n",
    "pipe_lr = Pipeline([('scl', preprocessing.StandardScaler()),\n",
    "            ('pca', PCA(n_components=2)),\n",
    "            ('clf', LogisticRegression(random_state=42))])\n",
    "\n",
    "pipe_svm = Pipeline([('scl', preprocessing.StandardScaler()),\n",
    "            ('pca', PCA(n_components=2)),\n",
    "            ('clf', svm.SVC(random_state=42))])\n",
    "pipe_dt = Pipeline([('scl', preprocessing.StandardScaler()),\n",
    "            ('pca', PCA(n_components=2)),\n",
    "            ('clf', tree.DecisionTreeClassifier(random_state=42))])\n",
    "\n",
    "# List of pipelines for ease of iteration\n",
    "pipelines = [pipe_lr, pipe_svm, pipe_dt]\n",
    "\n",
    "# Dictionary of pipelines and classifier types for ease of reference\n",
    "pipe_dict = {0: 'Logistic Regression', 1: 'Support Vector Machine', 2: 'Decision Tree'}\n",
    "\n",
    "# Fit the pipelines\n",
    "for pipe in pipelines:\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "# Compare accuracies\n",
    "for idx, val in enumerate(pipelines):\n",
    "    print('%s pipeline test accuracy: %.3f' % (pipe_dict[idx], val.score(X_test, y_test)))\n",
    "\n",
    "# Identify the most accurate model on test data\n",
    "best_acc = 0.0\n",
    "best_clf = 0\n",
    "best_pipe = ''\n",
    "for idx, val in enumerate(pipelines):\n",
    "    if val.score(X_test, y_test) > best_acc:\n",
    "        best_acc = val.score(X_test, y_test)\n",
    "        best_pipe = val\n",
    "        best_clf = idx\n",
    "print('Classifier with best accuracy: %s' % pipe_dict[best_clf])\n",
    "\n",
    "# Save pipeline to file\n",
    "joblib.dump(best_pipe, 'best_pipeline.pkl', compress=1)\n",
    "print('Saved %s pipeline to file' % pipe_dict[best_clf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
